1. Думаю, что основные проблемы связаны с правильной обработкой естественного языка. Как пример, могут быть слова с одиннаковым написанием, но разным лексическим значением, что полностью меняет картину статистики слов их классификации на части речи и тд. Отсюда следует вывод что естественный язык сложен для понимания текста, поэтому и нужно чтобы математическая модель работала не с символами, а со смысловым содержанием, что гораздо сложнее.
2. для определенных задач буду использовать определенные библиотеки и фреймворки такие как:
- Sentiment analysis: NLTK, SpaCy
- Multi-label classification: sk-learn
- Dependency parsing: NLTK, spaCy
- POS-tagging: spaCy
- NER: spaCy, NLTK
3. для оценивания построенной математической модели, которая классифицирует по каким-то признакам, буду использовать метрики:
	1. прежде всего составим матрицу ошибок
	2. затем измерим accuraccy
	3. можно вопсользоваться и f-мерой
	4. recall и precision (Отнес в один пункт, тк суть почти одна и таже)
все это поможет понять насколько точной была классификация, и какие решения были правильными, а какие нет.
 
4. --->	1. разбиваем текст на отдельные слова (токены)
	2. выделяем только значимые слова, вычеркивая все местоимения, предлоги и тому подобные конструкции, не имеющие 	никакой важности и веса.
	3. нормализуем наши данные, чтобы все было в текстовом варианте.удаляем ошибки в словах.
	4. лематизация и стемминг - приводим все слова в начальную(неопределенную форму).
	
5. отвечать на этот вопрос нужно смотря на требования к проекту. Если нам нужно запустить продукт в пользование в максимально сжатые сроки, то я бы использовал построение проекта на основе микросервисов. Подобный подход позволяет разбить задачи на подзадачи, тем самым разработка проекта ведется быстрее, чем при монолитном способе. Если же стоит задача построить архитектуру продукта максимально гибкую, отлаженную, качественную, то, я думаю, стоит применять монолитное построение проекта. Это позволяет продумать все до мелочей, избавиться от каких-то проблем и багов, повышая при этом качество продукта.
6. в данный момент работаю над плагином для учета посещаемости студентов для системы moodle (используемый стек технологий такой: SQL, JS, PHP, HTML). Самая большая проблема - это грамотная разработка архитектуры бд, чтобы она была масштабируема и без лишних таблиц.
Так как студентов обычно много, нужно учитывать многие параметры, данные, чтобы все в бд было компактно и понятно. К сожалению проектом на гите поделиться не могу).
7. да, конечно, понимание как это работает есть.
8. нет.
9. подобными Tool'ами пользоваться не приходилось, но, думаю, что это удобно использовать при работе, исходя из статей, что читал про тот же Docker.
10. --
11. был опыт работы с большим количеством крупных файлов. на основе логов приходилось делать описательную статистику, строить графики, чтобы обьяснить что происходит с сайтом в определенное время дня. это помогло минимизировать вычислительные мощности для поддержки работы сайта, а так же понять при каких условиях и в какое время дня сайт ложится, выдавая ошибку 502.